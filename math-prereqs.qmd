# Mathematics

{{< include macros.qmd >}}

These lecture notes use:

- algebra
- precalculus
- univariate calculus
- linear algebra
- vector calculus

Some key results are listed here.

## Derivatives

:::{#thm-product-rule}
#### Product rule
$$(ab)' = ab' + ba'$$
:::

:::{#thm-quotient-rule}
#### Quotient rule
$$(a/b)' = 1/b - (a/b^2)b'$$ 
:::

:::{#thm-chain-rule}
#### Chain rule
$$\derivf{a}{c} = \derivf{a}{b} \derivf{b}{c}$$
:::

## Logarithms and Exponentials

:::{#thm-log-prod}
#### logarithm of a product is the sum of the logs of the factors
$$
\log{a\cd b} = \log{a} + \log{b}
$$

:::

:::{#cor-log-quot}
#### logarithm of a quotient

::: notes
The logarithm of a quotient is equal to the difference of the logs of the factors:
:::

$$\log{\frac{a}{b}} = \log{a} - \log{b}$$
:::

:::{#thm-log-exp}
#### logarithm of an exponential function
$$
\log{a^b} = b \cd \log{a}
$$

:::

:::{#thm-exp-sum}
#### exponential of a sum

::: notes
The exponential of a sum is equal to the product of the exponentials of the addends:
:::

$$\exp{a+b} = \exp{a} \cd \exp{b}$$

:::

:::{#thm-deriv-log}

#### derivative of logarithm
$$\dlogf{x} = \frac{1}{x} = x^{-1}$$
:::

:::{#thm-deriv-exp}
#### derivative of exponential
$$\dexpf{x} = \expf{x}$$
:::

---

:::{#cor-deriv-log-chain}

#### Chain rule for logarithms
$$
\deriv{x}\log{f(x)} = \frac{f'(x)}{f(x)}
$$

:::

::: proof
Apply @thm-chain-rule and @thm-deriv-log.
:::

---

## Vector Calculus {#sec-vector-calculus}

(adapted from @fieller2018basics, ยง7.2)

Let $\vx$ and $\vb$ be vectors of length $p$, 
or in other words, matrices of length $p \times 1$:

$$
\vx = \begin{bmatrix}
x_{1} \\
x_{2} \\
\vdots \\
x_{p}
\end{bmatrix} \\
$$

$$
\vb = \begin{bmatrix}
\beta_{1} \\
\beta_{2} \\
\vdots \\
\beta_{p}
\end{bmatrix}
$$

:::{#def-transpose}
#### Transpose

The transpose of a row vector is the column vector with the same 
sequence of entries:

$$
\vx' \equiv \vx^\top \equiv [x_1, x_2, ..., x_p]
$$

:::

:::{#exm-dot-product}
#### Dot product as matrix multiplication

$$
\vx\'\vb
= [x_1, x_2, ..., x_p] 
\begin{bmatrix}
\beta_{1} \\
\beta_{2} \\
\vdots \\
\beta_{p}
\end{bmatrix} = 
x_1\beta_1+x_2\beta_2 +...+x_p \beta_p 
$$
:::

:::{#thm-transpose-sum}
#### Transpose of a sum
$$(\vx+\vy)\' = \vx\' + \vy\'$$
:::

---

::: {#def-vector-derivative}
#### Vector derivative
If $f(\vb)$ is a function that takes a vector $\vb$ as input and outputs a scalar, 
such as $f(\vb) = x'\vb$, 
then:

$$
\deriv{ \vb} f(\vb) = 
\begin{bmatrix}
\deriv{\beta_1}f(\vb) \\
\deriv{\beta_2}f(\vb) \\
\vdots \\
\deriv{\beta_p}f(\vb)
\end{bmatrix}
$$
:::

---

:::{#thm-deriv-lincom}

#### Derivative of a linear combination

$$
\deriv{\vb} \vx\' \vb = x
$$

:::: notes
This looks a lot like non-vector calculus, except that you have to transpose the coefficient.
::::
:::

---

::: proof

If $f(\beta) = x\'\beta$, then:

$$ 
\deriv{ \beta} x\'\beta= 
\begin{bmatrix}
\deriv{\beta_1}(x_1\beta_1+x_2\beta_2 +...+x_p \beta_p ) \\
\deriv{\beta_2}(x_1\beta_1+x_2\beta_2 +...+x_p \beta_p ) \\
\vdots \\
\deriv{\beta_p}(x_1\beta_1+x_2\beta_2 +...+x_p \beta_p )
\end{bmatrix} 
=
\begin{bmatrix}
x_{1} \\
x_{2} \\
\vdots \\
x_{p}
\end{bmatrix}
= \vx
$$

:::

---

:::{#thm-deriv-normsq}

#### Derivative of a vector quadratic

$$
\deriv{\vb} \vb'\vb = 2\vb
$$

:::

::: notes
This is like taking the derivative of $x^2$.
:::

---

:::{#thm-quadratic-form}

If $S$ is a $p\times p$ matrix, then:

$$
\deriv{\beta} \beta'S\beta = 2S\beta
$$

:::
 
::: notes
Again, this is like taking the derivative of $cx^2$ with respect to $x$ in non-vector calculus.
:::

## Additional resources

### Calculus 

- @khuri2003advanced

### Linear Algebra and Vector Calculus

- @fieller2018basics
- @banerjee2014linear
- @searle2017matrix

### Numerical Analysis

- [Hua Zhou](https://hua-zhou.github.io/)'s [lecture notes for "UCLA Biostat 216 - Mathematical Methods for Biostatistics" (2023 Fall)](https://ucla-biostat-216.github.io/2023fall/schedule/schedule.html)
